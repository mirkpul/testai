{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start creating a dummy dataset with Function data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:\n",
      "(100000, 3)\n",
      "(100000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "funData = []\n",
    "resultData = []\n",
    "\n",
    "for x in range(1,100001):\n",
    "    funData.append([x,x+1,x+2])\n",
    "    resultData.append([(x+x+1+x+2)*2])\n",
    "\n",
    "print(\"Dataset size:\")\n",
    "print(np.array(funData).shape)\n",
    "print(np.array(resultData).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_features = StandardScaler()\n",
    "X_scaled = scaler_features.fit_transform(funData)\n",
    "scaler_labels = StandardScaler()\n",
    "Y_scaled = scaler_labels.fit_transform(resultData)\n",
    "#X_scaled = np.array(funData)\n",
    "#Y_scaled = np.array(resultData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. splitting into train and test\n",
    "train_size_perc = 0.9\n",
    "train_limit = len(X_scaled) * train_size_perc\n",
    "X_scaled_train = X_scaled[:int(train_limit)]\n",
    "X_scaled_test = X_scaled[int(train_limit):]\n",
    "Y_scaled_train = Y_scaled[:int(train_limit)]\n",
    "Y_scaled_test = Y_scaled[int(train_limit):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "window = 5\n",
    "features_reshaped_train = []\n",
    "features_reshaped_test = []\n",
    "labels_reshaped_train = []\n",
    "labels_reshaped_test = []\n",
    "\n",
    "#resizing X_scaled_train sliding window from the beginning to the end\n",
    "for i in range(0, len(X_scaled_train) - window +1):\n",
    "    #appending sub list of window size\n",
    "    features_reshaped_train.append(X_scaled_train[i:i + window][:,[0,1,2]])\n",
    "    #feeding labels with third features of the last window item. Optional\n",
    "    #labels.append(Y_scaled[i + window - 1])\n",
    "\n",
    "#resizing X_scaled_test sliding window from the beginning to the end\n",
    "for i in range(0, len(X_scaled_test) - window +1):\n",
    "    #appending sub list of window size\n",
    "    features_reshaped_test.append(X_scaled_test[i:i + window][:,[0,1,2]])\n",
    "    #feeding labels with third features of the last window item. Optional\n",
    "    #labels.append(Y_scaled[i + window - 1])\n",
    "\n",
    "#resizing Y_scaled_train sliding window from the beginning to the end\n",
    "for i in range(0, len(Y_scaled_train) - window + 1):\n",
    "    #appending sub list of window size\n",
    "    labels_reshaped_train.append(Y_scaled_train[i + window - 1])\n",
    "    #feeding labels with third features of the last window item. Optional\n",
    "    #labels.append(Y_scaled[i + window - 1])\n",
    "\n",
    "#resizing Y_scaled_test sliding window from the beginning to the end\n",
    "for i in range(0, len(Y_scaled_test) - window +1):\n",
    "    #appending sub list of window size\n",
    "    labels_reshaped_test.append(Y_scaled_test[i + window - 1])\n",
    "    #feeding labels with third features of the last window item. Optional\n",
    "    #labels.append(Y_scaled[i + window - 1])\n",
    "    \n",
    "print(np.array(features_reshaped_train).shape)\n",
    "print(np.array(features_reshaped_test).shape)\n",
    "print(np.array(labels_reshaped_train).shape)\n",
    "print(np.array(labels_reshaped_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an ANN predicting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "def create_model(window):\n",
    "    model = Sequential()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(window,3)))\n",
    "    model.add(Dense (1))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8995 samples, validate on 996 samples\n",
      "Epoch 1/10\n",
      "8995/8995 [==============================] - 5s 596us/step - loss: 0.0204 - acc: 1.1117e-04 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8995/8995 [==============================] - 4s 397us/step - loss: 1.0106e-04 - acc: 1.1117e-04 - val_loss: 1.1014e-04 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "8995/8995 [==============================] - 3s 377us/step - loss: 8.4364e-06 - acc: 1.1117e-04 - val_loss: 9.5424e-05 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "8995/8995 [==============================] - 4s 390us/step - loss: 5.2781e-06 - acc: 1.1117e-04 - val_loss: 1.7906e-05 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "8995/8995 [==============================] - 4s 404us/step - loss: 2.9116e-06 - acc: 1.1117e-04 - val_loss: 8.1401e-07 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "8995/8995 [==============================] - 4s 396us/step - loss: 1.6207e-06 - acc: 1.1117e-04 - val_loss: 4.8491e-06 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "8995/8995 [==============================] - 4s 409us/step - loss: 7.6445e-07 - acc: 1.1117e-04 - val_loss: 2.1695e-05 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "8995/8995 [==============================] - 4s 459us/step - loss: 4.6484e-07 - acc: 1.1117e-04 - val_loss: 2.9968e-05 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "8995/8995 [==============================] - 4s 414us/step - loss: 4.2048e-07 - acc: 1.1117e-04 - val_loss: 4.6996e-05 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "8995/8995 [==============================] - 4s 405us/step - loss: 3.2871e-07 - acc: 1.1117e-04 - val_loss: 4.4484e-05 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7fb32fc748>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(window)\n",
    "\n",
    "X_train = np.array(features_reshaped_train)\n",
    "Y_train = np.array(labels_reshaped_train)\n",
    "X_test = np.array(features_reshaped_test)\n",
    "Y_test = np.array(labels_reshaped_test)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32,epochs=10,verbose=1, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 42381.50390625]]\n"
     ]
    }
   ],
   "source": [
    "test_data = [[5000,5001,5002],[6000,6001,6002],[7000,7001,7002],[8000,8001,8002],[9000,9001,9002]]\n",
    "\n",
    "test_data = scaler_features.transform(test_data)\n",
    "\n",
    "test_predict = scaler_labels.inverse_transform(model.predict(test_data.reshape(1,5,3)))\n",
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
