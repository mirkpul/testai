{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start creating a dummy dataset with multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "multiplyData = []\n",
    "resultData = [] \n",
    "resultDataRaw = []\n",
    "for it in range(1,1001):\n",
    "    for x in range(1,11):\n",
    "        for y in range(1,11):\n",
    "            multiplyData.append([x,y])\n",
    "            res = []\n",
    "            for i in range(1,101):\n",
    "                if(i == (x*y)):\n",
    "                    res.append(1)\n",
    "                else:\n",
    "                    res.append(0)\n",
    "            resultData.append(res)\n",
    "            resultDataRaw.append(x*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an ANN predicting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1024, activation='relu', input_shape=(2,)))\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_model_raw():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1024, activation='relu', input_shape=(2,)))\n",
    "    #model.add(Dropout(0.8))\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = np.array(multiplyData)\n",
    "Y = np.array(resultData)\n",
    "Y_raw = np.array(resultDataRaw)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X_scaled, Y, test_size=0.1, random_state=42)\n",
    "features_train_raw, features_test_raw, labels_train_raw, labels_test_raw = train_test_split(X_scaled, Y_raw, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "90000/90000 [==============================] - 11s 125us/step - loss: 1.0428 - acc: 0.7321 - val_loss: 0.2816 - val_acc: 0.9475\n",
      "Epoch 2/5\n",
      "90000/90000 [==============================] - 11s 120us/step - loss: 0.1210 - acc: 0.9985 - val_loss: 0.0423 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "90000/90000 [==============================] - 11s 120us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "90000/90000 [==============================] - 11s 123us/step - loss: 0.0093 - acc: 0.9986 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "90000/90000 [==============================] - 11s 125us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7df41e7b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(features_train, labels_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    verbose=1, validation_data=(features_test,labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "90000/90000 [==============================] - 6s 69us/step - loss: 47.8892 - acc: 0.0058 - val_loss: 0.3318 - val_acc: 0.0094\n",
      "Epoch 2/5\n",
      "90000/90000 [==============================] - 6s 64us/step - loss: 0.0949 - acc: 0.0100 - val_loss: 0.0215 - val_acc: 0.0094\n",
      "Epoch 3/5\n",
      "90000/90000 [==============================] - 6s 64us/step - loss: 0.0096 - acc: 0.0101 - val_loss: 0.0043 - val_acc: 0.0094\n",
      "Epoch 4/5\n",
      "90000/90000 [==============================] - 6s 64us/step - loss: 0.0022 - acc: 0.0101 - val_loss: 6.9433e-04 - val_acc: 0.0094\n",
      "Epoch 5/5\n",
      "90000/90000 [==============================] - 6s 63us/step - loss: 0.0012 - acc: 0.0101 - val_loss: 0.0032 - val_acc: 0.0094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7ba39af28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw = create_model_raw()\n",
    "\n",
    "model_raw.fit(features_train_raw, labels_train_raw,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    verbose=1, validation_data=(features_test_raw,labels_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.18983412e-38\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.28926093e-35\n",
      "    1.19573841e-26   9.72814444e-35   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   6.27409942e-32   0.00000000e+00   3.70338074e-25\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   8.85854950e-29\n",
      "    0.00000000e+00   0.00000000e+00   1.76579461e-23   3.48946869e-15\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   3.38657356e-24   0.00000000e+00   1.08396954e-13\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   9.04947470e-15\n",
      "    2.82492383e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.00506711e-05   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   9.99951720e-01]]\n",
      "99.8767\n"
     ]
    }
   ],
   "source": [
    "test_data = [[10,10]]\n",
    "\n",
    "factor_1 = 1.0\n",
    "factor_2 = 1.0\n",
    "\n",
    "if(test_data[0][0] > 10):\n",
    "    factor_1 = test_data[0][0] / 10\n",
    "\n",
    "if(test_data[0][1] > 10):\n",
    "    factor_2 = test_data[0][1] / 10\n",
    "    \n",
    "print(factor_1)\n",
    "print(factor_2)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "test_predict = model.predict(test_data)\n",
    "print(test_predict)\n",
    "\n",
    "test_predict_raw = model_raw.predict(test_data)\n",
    "print(test_predict_raw[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
